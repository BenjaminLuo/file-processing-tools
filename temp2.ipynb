{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def _apply_filters(file_path: str, filters: dict) -> bool:\n",
    "    file = Path(file_path).resolve()\n",
    "    if filters.get('exclude_str') and \\\n",
    "            set(os.path.normpath(str(file)).split(os.path.sep)) & set(filters['exclude_str']):\n",
    "        return False\n",
    "    if filters.get('include_str') and \\\n",
    "            not set(os.path.normpath(str(file)).split(os.path.sep)) & set(filters['include_str']):\n",
    "        return False\n",
    "    if filters.get('extensions') and file.suffix not in filters['extensions']:\n",
    "        return False\n",
    "    if filters.get('exclude_extensions') and file.suffix in filters['exclude_extensions']:\n",
    "        return False\n",
    "    if filters.get('min_size') and file.stat().st_size < filters['min_size']:\n",
    "        return False\n",
    "    if filters.get('max_size') and file.stat().st_size > filters['max_size']:\n",
    "        return False\n",
    "\n",
    "    return True  # Passes all filter conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 186 files completed [00:01, 104.31 files completed/s]ed]\n",
      "Processing batches: 1 batches completed [00:01,  1.79s/ batches completed]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from file_processing import File\n",
    "\n",
    "def process(file_path, report_path, batch_size=1000, breakpoint=0, filters=None, recovery_mode=False):\n",
    "\n",
    "    # Crash recovery: auto-computing breakpoint to start processing\n",
    "    if recovery_mode and os.path.isfile(report_path):\n",
    "        df = pd.read_csv(report_path)\n",
    "        breakpoint = len(df)\n",
    "\n",
    "    with tqdm(desc='Processing batches', unit=' batches completed') as pbar:\n",
    "        for index, batch in enumerate(loader(file_path, batch_size=batch_size, breakpoint=breakpoint, filters=filters)):\n",
    "            data = pd.DataFrame([file.processor.__dict__ for file in batch])\n",
    "\n",
    "            if index > 1:\n",
    "                df = pd.read_csv(report_path)\n",
    "                df = pd.concat([df, data], ignore_index=True)\n",
    "                df.to_csv(report_path, index=False)\n",
    "            elif not recovery_mode:\n",
    "                data.to_csv(report_path, index=False)\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "\n",
    "def loader(file_path, batch_size=0, breakpoint=0, filters=None):\n",
    "    batch = []\n",
    "\n",
    "    with tqdm(desc='Processing files', unit=' files completed') as pbar:\n",
    "        for dirpath, _, filenames in os.walk(file_path):\n",
    "            for filename in filenames:\n",
    "                pbar.update(1)\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "\n",
    "                if filters and not _apply_filters(file_path, filters):\n",
    "                    continue\n",
    "\n",
    "                if pbar.n > breakpoint:\n",
    "                    file_obj = File(file_path, open_file=False)\n",
    "\n",
    "                    if batch_size == 0:\n",
    "                        yield file_obj\n",
    "                    elif batch_size > 0:\n",
    "                        batch.append(file_obj)\n",
    "                        batch_progress = pbar.n/batch_size\n",
    "\n",
    "                        if int(batch_progress) == batch_progress:\n",
    "                            yield batch\n",
    "                            batch = []\n",
    "\n",
    "        if len(batch) > 0:\n",
    "            yield batch\n",
    "\n",
    "process('./tests', report_path='metadata.csv', batch_size=1000, recovery_mode=False, filters={'exclude_str': ['.venv', '.git']})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
